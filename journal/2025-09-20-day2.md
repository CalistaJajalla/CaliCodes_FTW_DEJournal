# Journal â€” 2025-09-20 (Day 2)

## 1) What I learned (bullets, not prose)
- Why **joins** matter in SQL (INNER vs LEFT JOIN) and how they change what rows appear  
- The meaning of **primary keys (PKs)** and **foreign keys (FKs)** in relational databases  
- The steps of **normalization** (1NF, 2NF, 3NF, BCNF) and how they prevent messy anomalies  
- That **OLTP vs OLAP** is like two worlds: one for transactions, one for analytics  
- How **dimensional modeling (Kimball)** works, with **facts as verbs/measures** and **dimensions as nouns/descriptors**  
- Why **testing in dbt** is like checking if the data â€œmakes senseâ€ (not just if the pipeline runs)  

## 2) New vocabulary (define in your own words)
- **INNER JOIN** â€“ Match only when both tables agree. Like â€œshow me albums *with* an artist.â€  
- **LEFT JOIN** â€“ Keep everyone from the left table, even if no match exists. Like â€œall customers, even if they bought nothing.â€  
- **Normalization** â€“ Break down big messy tables into smaller, cleaner ones so updates donâ€™t go haywire.  
- **1NF** â€“ Each column should be atomic âš›ï¸, no lists hiding inside.  
- **2NF** â€“ Attributes depend on the *whole* key ğŸ”‘, not just part of it.  
- **3NF** â€“ Attributes depend only on the key ğŸ”, not on other attributes.  
- **BCNF** â€“ Hardcore version of 3NF: every determinant must be a candidate key.  
- **OLTP** â€“ Databases for speed and transactions (banking, orders).  
- **OLAP** â€“ Databases for analysis and big-picture reports.  
- **dbt test** â€“ Sanity checks for data, like â€œare emails unique?â€  

## 3) Data Engineering mindset applied (what principles did I use?)
- **Donâ€™t trust raw data blindly.** Normalization showed me how duplicate emails or genres could ruin insights.  
- **Think in trade-offs.** INNER JOIN vs LEFT JOIN isnâ€™t just syntax â€” itâ€™s a business decision on â€œwho counts.â€  
- **Facts vs Dimensions.** Treat measures and descriptors separately so analysis is clean and flexible.  
- **Testing is not fixing.** Data tests are like observability â€” you shine light on problems early, before they reach dashboards.  
  
![Alt text](../assets/NAN.jpg "NAN")

## 4) Decisions & assumptions (why, alternatives, trade-offs)
- When testing SQL queries, I chose to **ORDER BY + LIMIT** instead of pulling everything.  
  - *Trade-off:* safer and faster for my laptop, but sometimes I might miss hidden rows or edge cases.  
- In joins, I practiced **LEFT JOIN** to catch customers with no purchases.  
  - Assumption: knowing â€œwhoâ€™s missingâ€ is as important as â€œwhoâ€™s buying.â€  
- I leaned on **GROUP BY + HAVING** instead of just WHERE when summarizing sales.  
  - *Trade-off:* WHERE feels simpler, but HAVING gives more power when working with aggregates.  

## 5) Open questions (things I still donâ€™t get)
- How do professional data teams decide when to **denormalize** data for speed, instead of sticking with 3NF/BCNF?  
- Is there a rule of thumb for **which dimension tables** should get Slowly Changing Dimension (SCD2) tracking?  
- If **dbt test** only logs failures, how do teams prevent bad data from reaching dashboards in production?  

## 6) Next actions (small, doable steps)
- Write at least **3 JOIN queries** using the Chinook dataset, testing INNER vs LEFT JOIN.  
- Try building my **own mini star schema** (Fact + Dimensions) from Chinook.
  - Update: Tried this but it looks rough? I think there are better ways to optimize or normalize it.
- Run a **dbt test** with intentional â€œbad dataâ€ to see how failures are logged.  


## 7) Artifacts & links (code, queries, dashboards)

<details>
<summary>Click to expand SQL practice</summary>

```sql
-- Customers with or without invoices --
SELECT c.FirstName, c.LastName, i.InvoiceId
FROM Customer c
LEFT JOIN Invoice i
ON c.CustomerId = i.CustomerId;

-- Top 5 longest tracks --
SELECT Name, Milliseconds
FROM Track
ORDER BY Milliseconds DESC
LIMIT 5;

-- Countries with sales > $100 --
SELECT BillingCountry, SUM(Total) AS sales
FROM Invoice
GROUP BY BillingCountry
HAVING SUM(Total) > 100;
```
</details> 

### Mini reflection (3â€“5 sentences)
What surprised me? What would I do differently next time? What will I watch out for in production?

Today stretched me the most with normalization. It feels abstract, but the water analogy (1NFâ€“BCNF = water safety levels) made it click.
I realized how easily bad design leads to contradictions (like duplicate emails).
Next time, Iâ€™ll practice designing tables from scratch instead of just querying them â€” so I see both sides (storage + analysis).

### BONUS: What is a meme that best describes what you feel or your learning today?

![Alt text](../assets/date-everywhere-data.gif "date is everywhere!")
